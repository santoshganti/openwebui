services:
  # OpenWebUI & its sidecars
  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: openwebui
    hostname: openwebui
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
    runtime: nvidia
    env_file:
      - .env
    environment:
      # OpenWebUI
      WEBUI_NAME: ${OPENWEBUI_WEBUI_NAME}
      WEBUI_URL: ${OPENWEBUI_WEBUI_URL}
      WEBUI_SECRET_KEY: ${OPENWEBUI_WEBUI_SECRET_KEY}
      OPENAI_API_KEY: ${OPENWEBUI_OPENAI_API_KEY}
      # Postgres
      DB_DATABASE_URL: ${OPENWEBUI_DB_DATABASE_URL}
      # PgVector
      VECTOR_DB: ${OPENWEBUI_VECTOR_DB}
      PGVECTOR_DB_URL: ${OPENWEBUI_PGVECTOR_DB_URL}
      # Ollama
      OLLAMA_BASE_URL: ${OPENWEBUI_OLLAMA_BASE_URL}
      # VALKEY
      REDIS_URL: ${OPENWEBUI_VALKEY_URL}
      # SMTP
      SMTP_SERVER: ${OPENWEBUI_SMTP_SERVER}
      SMTP_PORT: ${OPENWEBUI_SMTP_PORT}
      SMTP_USERNAME: ${OPENWEBUI_SMTP_USERNAME}
      SMTP_PASSWORD: ${OPENWEBUI_SMTP_PASSWORD}
      SMTP_USE_TLS: ${OPENWEBUI_SMTP_USE_TLS}
      SMTP_FROM_EMAIL: ${OPENWEBUI_SMTP_FROM_EMAIL}
      SMTP_FROM_NAME: ${OPENWEBUI_SMTP_FROM_NAME}
    networks:
      openwebui:
        ipv4_address: ${OPENWEBUI_WEBUI_APP_IP}
      pgvector: null
      valkey: null
      searxng: null # Add SearXNG network access
      aux: null
    # dns:
    #   - 192.168.6.1
    #   - 10.0.0.1
    extra_hosts:
      - host.docker.internal:host-gateway
    volumes:
      - ${APPDATA}/data:/app/backend/data
      - ${APPSTORAGE}/shared:/app/backend/shared
      - ${APPSTORAGE}/ollama:/root/.ollama
    depends_on:
      - pgvector
      - valkey
      - searxng # Add SearXNG dependency
      - tika
      - playwright
      - gotenberg
      # - docling-inference
    restart: unless-stopped

  # Ollama
  ollama:
    image: ollama/ollama:latest
    container_name: openwebui-ollama
    hostname: openwebui-ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
    runtime: nvidia
    tty: true
    pull_policy: always
    env_file:
      - .env
    environment:
      OLLAMA_KEEP_ALIVE: ${OPENWEBUI_OLLAMA_KEEP_ALIVE}
    networks:
      - ollama
    ports:
      - 11434:11434
    volumes:
      - ${APPSTORAGE}/shared:/code
      - ${APPSTORAGE}/ollama:/root/.ollama
    restart: unless-stopped

  # Vector Database: pgvector Database - Enhanced performance and enterprise features
  pgvector:
    image: pgvector/pgvector:pg17
    container_name: openwebui-pgvector
    hostname: ${OPENWEBUI_PGVECTOR_HOST}
    env_file:
      - .env
    tmpfs:
      - /dev/shm:size=128m
    environment:
      POSTGRES_USER: ${OPENWEBUI_PGVECTOR_USER}
      POSTGRES_PASSWORD: ${OPENWEBUI_PGVECTOR_PASSWORD}
      POSTGRES_DB: ${OPENWEBUI_PGVECTOR_DB}
      PGVECTOR_MAX_VECTOR_LENGTH: ${OPENWEBUI_PGVECTOR_MAX_VECTOR_LENGTH}
      POSTGRES_MAX_CONNECTIONS: ${OPENWEBUI_POSTGRES_MAX_CONNECTIONS}
      PGVECTOR_CHUNK_SIZE: ${OPENWEBUI_PGVECTOR_CHUNK_SIZE}
      UVICORN_WORKERS: ${OPENWEBUI_UVICORN_WORKERS}
    networks:
      - pgvector
    volumes:
      - ${DATABASE}/pgvector_data:/var/lib/postgresql/data
    restart: unless-stopped

  # Valkey - Required for clustering and websocket support
  valkey:
    image: valkey/valkey:8
    container_name: openwebui-valkey
    hostname: ${OPENWEBUI_VALKEY_HOST}
    env_file:
      - .env
    tmpfs:
      - /dev/shm:size=128m
    networks:
      - valkey
    volumes:
      - ${DATABASE}/valkey:/data
    command: valkey-server --requirepass "${OPENWEBUI_VALKEY_PASSWORD}" --save ""
    restart: unless-stopped

  # SearXNG - Dedicated Privacy-Focused Search Engine
  searxng:
    image: searxng/searxng:latest
    container_name: openwebui-searxng
    hostname: openwebui-searxng
    tty: true
    env_file:
      - .env
    environment:
      # SearXNG Configuration
      # Disable rate limiting entirely
      SEARXNG_BIND_ADDRESS: 0.0.0.0
      SEARXNG_LIMITER: 'false'
      SEARXNG_PUBLIC_INSTANCE: 'false'
      SEARXNG_BASE_URL: ${OPENWEBUI_SEARXNG_BASE_URL:-http://localhost:8080}
      SEARXNG_SECRET_KEY: ${OPENWEBUI_SEARXNG_SECRET_KEY}
      SEARXNG_SETTINGS_PATH: ${OPENWEBUI_SEARXNG_SETTINGS_PATH}
      # Redis for caching (optional, can use Valkey)
      SEARXNG_REDIS_URL: ${OPENWEBUI_VALKEY_URL}
    networks:
      openwebui:
        ipv4_address: ${OPENWEBUI_SEARXNG_APP_IP} # External access via MacVLAN
      searxng: null
      valkey: null # Share cache with OpenWebUI
      pgvector: null
    ports:
      - ${SEARXNG_PORT:-8080}:8080 # External access port
    volumes:
      - ${APPDATA}/searxng/config/settings.yml:/etc/searxng/settings.yml:ro
      - ${APPDATA}/searxng/log:/var/log/searxng
    depends_on:
      - valkey
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    logging:
      driver: json-file
      options:
        max-size: 1m
        max-file: '1'
    restart: unless-stopped

  # Chromium version from the github page
  # & likely ghcr container registry because docker registry has capped pull
  # github packages - https://github.com/browserless/browserless/pkgs/container/chromium
  # github repo - https://github.com/browserless/browserless
  playwright:
    image: ghcr.io/browserless/chromium:latest
    container_name: openwebui-playwright
    hostname: openwebui-playwright
    environment:
      MAX_CONCURRENT_SESSIONS: 10
      MEMORY_LIMIT: 2048
    networks:
      - searxng
    ports:
      - 30200:3000
    restart: unless-stopped

  # docling - This project provides a FastAPI wrapper around the docling document parser
  # to make it easier to use in distributed production environments.
  # github - https://github.com/aidotse/docling-inference
  # docling-inference:
  #   image: ghcr.io/aidotse/docling-inference:latest
  #   container_name: openwebui-docling
  #   hostname: ${OPENWEBUI_DOCKLING_HOST}
  #   env_file:
  #     - .env
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: all
  #             capabilities:
  #               - gpu
  #   runtime: nvidia
  #   environment:
  #     - NUM_WORKERS=${OPENWEBUI_NUM_WORKERS}
  #   networks:
  #     - aux
  #   ports:
  #     - 5001:8080
  #   volumes:
  #     - ${APPDATA}/docling/hf_cache:/root/.cache/huggingface
  #     - ${APPDATA}/docling/ocr_cache:/root/.EasyOCR
  #   restart: unless-stopped

  # paperless-tika server
  tika:
    image: docker.io/apache/tika:latest
    container_name: openwebui-tika
    hostname: ${OPENWEBUI_TIKA_HOST}
    env_file:
      - .env
    networks:
      - aux
    ports:
      - 9998:9998
    restart: unless-stopped

  # gotenberg - office files and eml files validation
  gotenberg:
    image: docker.io/gotenberg/gotenberg:8.7
    container_name: openwebui-gotenberg
    hostname: ${OPENWEBUI_GOTENBERG_HOST}
    env_file:
      - .env
    networks:
      - aux
    ports:
      - 3000:3000
    # The gotenberg chromium route is used to convert .eml files. We do not
    # want to allow external content like tracking pixels or even javascript.
    command:
      - gotenberg
      - --chromium-disable-javascript=true
      - --chromium-allow-list=file:///tmp/.*
    restart: unless-stopped

  ## AUX Containers: vscode Server
  # vscode:
  #   image: lscr.io/linuxserver/code-server:latest
  #   container_name: openwebui-vscode
  #   hostname: openwebui-vscode
  #   tmpfs:
  #     - /dev/shm:size=128m
  #   env_file:
  #     - .env
  #   environment:
  #     SUDO_PASSWORD: ${OPENWEBUI_VSCODE_SUDO_PASSWORD}
  #     DEFAULT_WORKSPACE: ${OPENWEBUI_VSCODE_DEFAULT_WORKSPACE}
  #     KEEPALIVE_INTERVAL: ${OPENWEBUI_VSCODE_KEEPALIVE_INTERVAL}
  #     KEEPALIVE_TIMEOUT: ${OPENWEBUI_VSCODE_KEEPALIVE_TIMEOUT}
  #     PROXY_DOMAIN: ${OPENWEBUI_VSCODE_PROXY_DOMAIN}
  #   networks:
  #     openwebui:
  #       ipv4_address: ${OPENWEBUI_VSCODE_APP_IP}
  #     pgvector: null
  #     valkey: null
  #     searxng: null # Add SearXNG access
  #   dns:
  #     - 192.168.6.1
  #     - 10.0.0.1
  #   ports:
  #     - 8443:8443
  #   volumes:
  #     - ./configs/apt-cacher-ng.conf:/etc/apt/apt.conf.d/apt-cacher-ng
  #     - ./configs/sudo.conf:/etc/sudoers.d/sudo.conf
  #     - ${APPDATA_VSCODE}/config:/config
  #     - ${APPDATA_VSCODE}/linuxbrew:/home/linuxbrew
  #     - ${APPDATA_VSCODE}/flatpak:/config/.local/share/flatpak
  #     - ${APPDATA_VSCODE}/workspace:/config/workspace
  #     - ${HOME_VSCODE}/.local:/config/.local
  #     - ${HOME_VSCODE}/.pyenv:/config/.pyenv
  #     - ${HOME_VSCODE}/.ssh:/config/.ssh
  #     - ${HOME_VSCODE}/.nvm:/config/.nvm
  #     - ${APPSTORAGE}/shared:/config/workspace/shared
  #   depends_on:
  #     - pgvector
  #     - valkey
  #     - searxng
  #     - tika
  #     - playwright
  #     - docling-inference
  #     - gotenberg
  #   restart: unless-stopped

  # Monitoring for postgres: Adminer
  adminer:
    image: adminer:latest
    container_name: openwebui-adminer
    hostname: openwebui-adminer
    env_file:
      - .env
    environment:
      ADMINER_PLUGINS: ${OPENWEBUI_ADMINER_PLUGINS}
      ADMINER_DEFAULT_SERVER: ${OPENWEBUI_ADMINER_DEFAULT_SERVER}
    networks:
      openwebui:
        ipv4_address: ${OPENWEBUI_ADMINER_APP_IP}
    depends_on:
      - pgvector
    restart: unless-stopped

networks:
  openwebui:
    name: unifi
    external: true
  ollama:
    internal: true
  pgvector:
    internal: true
  valkey:
    internal: true
  searxng:
    internal: true
  aux:
    internal: true
