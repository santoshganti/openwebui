{"path":"clippings/2106.07857v1.pdf","text":"JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 1 Bilateral Personalized Dialogue Generation with Dynamic Persona-Aware Fusion Bin Li, Bin Sun, Member, IEEE and Shutao Li, Fellow, IEEE Abstractâ€”Generating personalized responses is one of the major challenges in natural human-robot interaction. Current researches in this ï¬eld mainly focus on generating responses consistent with the robotâ€™s pre-assigned persona, while ignoring the userâ€™s persona. Such responses may be inappropriate or even offensive, which may lead to the bad user experience. Therefore, we propose a bilateral personalized dialogue generation (BPDG) method with dynamic persona-aware fusion via multi-task trans- fer learning to generate responses consistent with both personas. The proposed method aims to accomplish three learning tasks: 1) an encoder is trained with dialogue utterances added with corresponded personalized attributes and relative position (lan- guage model task), 2) a dynamic persona-aware fusion module predicts the persona presence to adaptively fuse the contextual and bilateral personas encodings (persona prediction task) and 3) a decoder generates natural, ï¬‚uent and personalized responses (dialogue generation task). To make the generated responses more personalized and bilateral persona-consistent, the Conditional Mutual Information Maximum (CMIM) criterion is adopted to select the ï¬nal response from the generated candidates. The experimental results show that the proposed method outperforms several state-of-the-art methods in terms of both automatic and manual evaluations. Index Termsâ€”Bilateral persona-consistent, conditional mutual information maximum, dynamic persona-aware fusion, multi- task transfer learning, personalized dialogue generation. I. INTRODUCTION O NE of the major challenges in human-robot interaction is to develop an intelligent agent to generate natural, personalized, information-rich, and consistent responses [1]. For this purpose, the dialogue agents have to learn to express personalized information appropriately like humans. Currently, personalized dialogue agents have been widely applied in various human-robot interaction scenarios, such as intelligent personal assistants [2], public service robots [3], wearable devices [4], etc. The agents with personalization are considered reliable and trustworthy, and can gain the userâ€™s conï¬dence and trust [5]. In the past decades, personalization has played an important role in the dialogue system and attracted wide attention [6]â€“ [10]. According to the different ways of personalized infor- mation modeling, the existing personalized dialogue systems are mainly categorized into two types: implicit personalization [7], [8] and explicit personalization [9], [10]. This work is supported by the National Key Research and Develop- ment Project(2018YFB1305200) and the National Natural Science Fund of China(61801178). Bin Li, Bin Sun, and Shutao Li are with College of Electrical and Informa- tion Engineering, and with the Key Laboratory of Visual Perception and Ar- tiï¬cial Intelligence of Hunan Province, Hunan University, Changsha, 410082, China. (libincn@hnu.edu.cn; sunbin611@hnu.edu.cn; shutao li@hnu.edu.cn). General GPT2 model with unilateral persona User: Where are you from? Robot: I am from Guangzhou. User: Come to my city and play with me? Robot: Yes, I want to go to Guangzhou. Our model with bilateral personas User: Where are you from? Robot: I come from Guangzhou. User: Come to my city and play with me? Robot: Yes, I want to go to Beijing. Userâ€™s personalized attributes Robotâ€™s personalized attributes \"Gender\" \"Female\" \"Gender\" \"Male\" \"Area\" \"Beijing\" \"Area\" \"Guangzhou\" \"Interests\" \"Shopping; Sport\" \"Interests\" \"Cooking; Movie\" Fig. 1. Exemplar dialogues with/without bilateral persona-consistent. The general GPT2 model with unilateral persona can generate a response that only meets the robotâ€™s persona, but ignores the persona of the other party. The proposed method can incorporate bilateral personas and generate a response that matches the personas of both parties. The implicit personalized dialogue system models personas with unstructured natural language utterances (e.g., â€œI am a musician.â€, â€œI like to play the guitar.â€), where the persona is implicitly mapped into the hidden state vectors. However, these implicit space mapping methods are poor in inter- pretability and may be over-ï¬tting during the training process. Besides, the given utterances are mostly short and limited to only a few personas, the model may fail to utilize the persona properly when generating responses [11]. Indeed, implicit personalized dialogue corpus [7] reï¬‚ecting personas in every response is also different from the way of interpersonal conversation. The explicit personalized dialogue system models the per- sonas with the structured personalized attributes, which are ex- plicitly formatted as different key-value pairs (e.g., <Gender, Female>, <Area, Beijing>). Such explicit persona modeling is more straightforward and interpretable. Speciï¬cally, the explicit personalized dialogue corpora [9], [10] are crawled on a large scale from social networking sites, such as Weibo1, where people may unintentionally show their personality dur- ing the conversation. However, the explicit personalization in [9] models the robotâ€™s persona in the form of a pre-assigned proï¬le and only emphasizes unilateral persona consisitency. The latest works [10], [12] incorporate the structured speakerâ€™s proï¬le into the generated response to ensure the persona consistency of the speaker. Although these methods solve the 1https://www.weibo.comarXiv:2106.07857v1 [cs.CL] 15 Jun 2021 JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 2 problem of unilateral persona consistency to some extent, the robot may ignore the userâ€™s persona during the conversation. As a result, the generated responses may conï¬‚ict with the userâ€™s personalized information. In the interpersonal conversations, both two interacting parties know each otherâ€™s personalized information [13]. When responding, the speaker should not only focus on their own personalized expression, but also consider the questions and persona of the other party [14]. As is shown in Fig. 1, during the conversation, the robot should generate responses consistent with the robotâ€™s own personalized attributes (i.e., unilateral persona-consistent). Furthermore, if the robot ig- nores the userâ€™s persona and generates responses inconsistent with the userâ€™s personalized attributes (i.e., bilateral persona- inconsistent), it may annoy the user and reduce the user experience. To solve the above problem, we propose a bilateral per- sonalized dialogue generation (BPDG) method with dynamic persona-aware fusion to generate responses consistent with both personas. Speciï¬cally, the BPDG method is based on the encoder-decoder structure of GPT2 [15] with multi-task transfer learning. The proposed method optimizes three tasks simultaneously: the language model task, the persona pre- diction task, and the dialogue generation task. In the lan- guage model task, the dialogue utterances embedded with the corresponded personalized attributes and relative position are used to train the encoder. In the persona prediction task, the dialogue contextual encoding is used to predict the possibilities of the personasâ€™ presence in the response, according to which the encodings of the dialogue context, bilateral personas and the right-shifted outputs are fused dynamically. In the dialogue generation task, the fused encoding is input into the decoder to generate response candidates with the beam search strategy [16]. Finally, in order to ensure the generated responses more personalized and bilateral persona-consistent, we adopt the Conditional Mutual Information Maximum (CMIM) criterion to select the ï¬nal response from the generated candidates. Thus, the proposed BPDG method can utilize bilateral per- sonalized information to generate personalized and bilateral persona-consistent responses for better user experience in the human-robot interaction. The main contributions of this article can be summarized as follows. 1) We propose a novel BPDG method, which integrates the bilateral personas to generate responses consistent with both personas. To the best of our knowledge, this is the very ï¬rst to propose the bilateral persona consistency in the personalized dialogue generation. 2) A dynamic persona-aware fusion module is developed to adaptively control the joint encodings of the bilateral personalized information, the dialogue context, and the shifted right outputs for decoding to generate bilateral persona-consistent responses. 3) We adopt the criterion of the CMIM in the person- alized dialogue generation, which makes the gener- ated responses more personalized and bilateral persona- consistent. 4) Both automatic and manual evaluations show that our method outperforms state-of-the-art methods. The remainder of this article is structured as follows. Section II reviews the work related to the personalized dia- logue system. Section III formulates the problem and details the proposed BPDG method. Section IV fully describes the experimental setups. Automatic and human evaluations are illustrated and analyzed in detail in Section V and Section VI respectively. Finally, the conclusions and some possible future work are pointed out in Section VII. II. RELATED WORK A. Personalized Dialogue Generation Inspiring by the â€œBig Fiveâ€ [17] in psychology, Mairesse et al. [18] take the lead in incorporating the personalities into the framework of dialogue generation, thereby generating responses with recognizable personality. However, the person- ality of the â€œBig Fiveâ€ is extremely implicit and subtle. It is necessary to build rules to capture personality characteristics. Besides, it is a challenge to construct a corpus with limited and laborious collection. With the popularity of deep learning, hand-craft rule modeling is gradually replaced by data-driven modeling. Li et al. [19] ï¬rst propose a personalized dialogue generation model, mapping the persona in natural utterance into distributed representation vectors on the seq2seq frame- work, which is beneï¬ted from the neural machine translation [20]. Subsequently, there are other different methods used for personalized dialogue generation modeling, for example, Song et al. [8] adopt the CVAE method implicitly learns the responses that contain personalized information to gen- erate personalized responses. Madotto et al. [21] design a personalized dialogue generation model with meta-learning. Yang et al. [22] describe an empirical survey of personalized dialogue generation via reinforcement learning. The above method is effective, but it also faces the problem of generating general or bilateral-inconsistent responses. Different from the previous work, the proposed BPDG method further integrates personalized information from both parties into the pre-trained encoder-decoder framework, to generate bilateral persona- consistent responses with multi-task learning and transfer learning. B. Transfer Learning Transfer learning aims to extract and transfer the knowledge from the source domain to the target domain [23], which has been very popular in the ï¬eld of the NLP in the past decade [24]. Recent advances in natural language generation rely on pre-training a large generative language model with a large corpus of unsupervised data. It mainly follows the two-stage paradigm of pre-training and ï¬ne-tuning. In the ï¬eld of personalized dialogue generation, Zhang et al. [25] ï¬rst introduce transfer learning into the two-stage personalized dialogue generation. Mazare et al. [26] pre-train a dialogue generation model on Reddit 2, and ï¬netune with the implicit personalized dialogue corpus, achieving better performance 2https://www.reddit.com JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 3 than the information retrieval method. Golovanov et al. [27] and Wolf et al. [28] show that transferring the pre-trained GPT2 model and ï¬ne-tuning in the downstream can signiï¬- cantly improve the quality of the generated responses. Zheng et al. [12] present a pre-training model that is ï¬rst pre-trained on the persona-sparse dialogue corpus, and utilize the speakerâ€™s persona in the ï¬ne-tuning stage. Our method also adopts the two-stage training paradigm based on the pre-trained model, transferring the knowledge learned from the vast unsupervised text into the encoder-decoder framework. C. Multi-task Learning Multi-task learning is known to fully improve the perfor- mance of the single task with multiple related tasks to be designed and optimized [29]. In the ï¬eld of personalized dialogue generation, multi-task learning is believed to enhance the effect of personalization [30]. Luan et al. [31] introduce autoencoder and seq2seq as subtasks into a conversational model, incorporating the speakerâ€™s persona into the generated responses. Wolf et al. [28] design a dialogue generation model that jointly learns two tasks (e.g., next sentence prediction and language model) when ï¬netuning. The experimental results show that multi-task learning can greatly improve the scores in automatic metrics. Golovanov et al. [32] integrate multi-task learning into the GPT2 framework with shared parameters, and designs three sub-tasks, including language model task, dialogue generation task and expected risk task. These tasks are proven to improve the performance in human evaluation. Shiv et al. [33] propose a multi-task learning toolkit for the personalized dialogue generation, which allows users to design different tasks for better dialogue generation performance. Zheng et al. [12] leverage target persona information in gen- erating unilateral persona-consistent responses by designing three different tasks, including the language model, persona routing, and dialogue generation. In this article, apart from the language model task and dialogue generation task, we further design a persona prediction task for the dynamic persona-aware fusion module, adaptively fusing the encodings of different information for decoding, to generate responses consistent with bilateral personas. III. PROPOSED METHOD In the interpersonal conversation, both interacting parties have their own personas such as gender, area, individual interests, etc. Such information may be presented in the response. In the human-robot dialogue, given the user persona U, the robot persona R, the personalized history H and the user input X, the robot generates a natural, ï¬‚uent and personalized response Y, which can be formulated as follows: Y = arg max Y â€² P (Y â€² | X, H, U, R) (1) where the user persona U and the robot persona R can be represented with the personal proï¬le, which is formatted as a set of attributes composed of key-value pairs. Each attribute in the user persona U = {u1, u2, . . . , um} is a key-value pair ui = âŸ¨ki, viâŸ©. The robot persona R is rep- resented likewise. The personalized history is represented as H = {{X U 1 , U } , { X R 2 , R} , . . . , { X R l , R}}, where the superscript indicates the speaker, and the subscript indicates the number of the dialogue rounds. Each sentence is associated with the persona of the corresponded speaker. The user input X = {X U l+1, U } contains the user current input X U l+1 with the user persona U . Combining the user input X and the personalized history H into the context of the dialogue C, the equation (1) can be further written as the equation (2): Y = arg max Y â€² P (Y â€² | C, U, R) (2) where the dialogue context C =< H, X > represents that the personalized history H is concatenated with the current user input X. Fig. 2. is the overview of the proposed BPDG method. The BPDG method consists of the encoder, the dynamic persona-aware fusion module, and the decoder. Following the GPT2 framework, the encoder and decoder share the same weights and act as a backbone to learn the sentence representation. The encoder trains the language model with the dialogue context embedding and encodes the embedding of the user persona and the robot persona independently. The dynamic persona-aware fusion module is used for the weighted fusion of the dialogue context encoding, the bilateral persona encodings and the shifted right outputs encoding. Afterwards, the fused encoding is sent into the decoder for generating several candidate responses with the beam search strategy. Finally, the CMIM criterion is adopted to output a personalized and bilateral persona-consistent response. A. Dialogue Context Modeling Dialogue context modeling means that each dialogue ut- terance embedding is added with the corresponded persona embedding and relative position embedding to obtain the embeddings of personalized history. The dialogue context embedding can be obtained by concatenating the embeddings of the personalized history and the current user input. The di- alogue context encoding is obtained with the dialogue context embedding being encoded. The process can be described as follows: 1) Utterence Embedding: The utterances of the user and the robot are ï¬rst embedded with word embedding respectively. The XU represents the embedded user input, and the XR represents the embedded robot output. Both embeddings are speciï¬ed with the same length n. If the corresponded length does not reach the speciï¬ed length, we use < P AD > as a placeholder. Otherwise, a truncation operation is taken. The word embedding process is shown as follows: XU = { xU 1 , xU 2 , x U 3 , . . . , xU n } (3) XR = {x R 1 , x R 2 , x R 3 , . . . , xR n } (4) where the XU is the embedding of the user input, the x U i is the word embedding of the i-th token in the sentence input by the user, and the XR is the embedding of the robot response, the xR i is the word embedding of the i-th token in the sentence output by the robot. JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 4 User Input Multi-head Attention User Persona Layer Norm Feed Forward + Layer Norm + Robot Persona Encoding Outputs Encoding (Shifted Right) User Persona Encoding Dialogue Context Encoding X 12 X 12 Multi-head Attention Layer Norm + DecoderEncoder Feed Forward Layer Norm Linear Output + Dynamic Persona-Aware Fusion Bilateral Attributes Robot Persona Dialogue History Personalized History Word Embbeding Word Embbeding Dialogue Context + Bilateral Personas Word Embbeding Word Embbeding ++ Position Embedding Position Embedding Position Embedding User Attributes + Fig. 2. The overview of the proposed BPDG method. 2) Persona Embedding: Persona embedding means the ut- terances embedded with the corresponded personas attributes. As is mentioned before, the proï¬le consists of three attributes: gender, area, and individual interests. The value of the gender is binary (i.e., 0 for male and 1 for female). The value of the area is represented with the index of the corresponded item in the look-up table. The items of the look-up table are sorted by the occurrence frequency of the area in the corpus. The individual interests are represented in a similar way. To take the operation of the user as an example, the process is shown in the equation (5): GU = {gU 1 , gU 2 , . . . , gU j , . . . , gU n | gU j = gU } AU = {a U 1 , a U 2 , . . . , a U j , . . . , a U n | a U j = a U } TU = {t U 1 , t U 2 , . . . , tU j , . . . , t U n | tU j = t U } (5) where the gU represents the word embedding of the userâ€™s gender extracted from the proï¬le, the gU j represents the gender embedding gU corresponding to the position j in the user input embedding XU , j âˆˆ [1, n]. The a U and t U represent the word embedding of the userâ€™s area and individual interests tag extracted from the proï¬le respectively. For multiple individual interests, we take the average of the ï¬rst-three embeddings of individual interests. The relative position embedding [34] is adopted to make the embedded tokens more sensitive to the position in the sentence for further attention operation. The position embedding is written as follows: Ei(2k) = sin ( i 10000 2k dmodel ) Ei(2k + 1) = cos ( i 10000 2k dmodel ) (6) where i is the position of the token in the sentence, k represents the k-th dimension of the word embedding, dmodel is the ï¬xed embedding dimension.2UserÂ InputRobotÂ Output ğ’™ SEP ğ’™ ğ’™UtteranceÂ Embeddings ğ’™ ğ’ˆ ğ’ˆ ğ’ˆ ğ’ˆGenderÂ Embeddings ğ’ˆ ğ’• ğ’• ğ’• ğ’•TagÂ Embeddings ğ’• ğ’‚ ğ’‚ ğ’‚ ğ’‚AreaÂ Embeddings ğ’‚ ğ¸ ğ¸ ğ¸ ğ¸PositionÂ Embeddings ğ¸ ğ’‰ ğ’‰HistoryÂ Embeddings++++++++++++++++++++.Â .Â ..Â .Â ..Â .Â ..Â .Â ..Â .Â ..Â .Â ..Â .Â ..Â .Â ..Â .Â ..Â .Â ..Â .Â ..Â .Â ..Â .Â ..Â .Â ..Â .Â ..Â .Â . Fig. 3. The structure of personalized history embeddings. 3) Personalized history embbedings: The Fig. 3. shows the structure of personalized history embeddings. The per- sonalized history embeddings are a combination of the afore- mentioned three types of embeddings, i.e., the embeddings of the utterance, the persona embeddings, and the position embeddings, with the < SEP > being used as the separator. Speciï¬cally, the personalized history embeddings are format- ted utterance by utterance with concatenation, which can be wrriten as the equation (7). H = Concat {h1, h2, . . . , hj, . . . , hl} hj = {DU , if mod (j, 2) = 0 DR, if mod (j, 2) = 1 , j âˆˆ [1, l] (7) where the Concat {} represents the operation of concatenation, l represents the total number of rounds of the personalized history, hj represents the personalized history of the j round, j âˆˆ [1, l]. For each utterance, the personalized history em- beddings are calculated via aligning the embeddings by token and performing token-wise aggregation. This process can be expressed as follows: DU = Add (XU , GU , AU , TU , E) (8) JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 5 Robot Persona Encoding Outputs Encoding User Persona Encoding Dialogue Context Encoding Masked Multi-head Attention Shifted Right EprevEREU Unmasked Multi-head Attention + Unmasked Multi-head Attention Unmasked Multi-head Attention EC Oenc OROUOC Oprev Persona Presence Prediction Ã— Ã—Ã— a b g Fig. 4. The structure of the dynamic persona-aware fusion module. DR = Add (XR, GR, AR, TR, E) (9) where the Add () represents the token-wise addition operation of the different embeddings with the same embedded length. 4) Dialogue Context embedding: The personalized history embeddings and the user current input at the l + 1 round are concatenated into the dialogue context embedding C, which can be expressed as follows: C = Concat {H, hl+1} (10) Finally, the dialogue context encoding EC is obtained after the dialogue context embedding C is encoded. B. Bilateral Proï¬le Modeling To take advantage of the bilateral personas in the dialogue generation, the explicit form of persona, i.e., the proï¬le, is used in the proposed method. Word embedding is performed on the proï¬le text to represent the semantic information in the same way as the utterance, which will beneï¬t the further processing. Speciï¬cally, the word embedding of the user persona U and the robot persona R can be written as follows: U = {u1, u2, u3 | ui = {s, v}, i = 1, 2, 3} (11) R = {r1, r2, r3 | ri = {s â€², vâ€²} , i = 1, 2, 3} (12) where each attribute ui in the embedded user persona U is the word embedding of the key-value pair. The embedded user persona U is the concatenation of the three attributes corresponding to gender, area, and individual interests respec- tively. The comma is used as the separator to concatenate each key-value pair. The embedded robot persona R is formatted likewise. Further, the embedded user persona U with relative position embedding E is input into the encoder to obtain the user persona encoding EU , while the embedded robot persona R turns into the ER is in the same way. The above process is implemented independently, which means that the EU and ER do not participate in the training of the encoder. C. Dynamic Persona-aware Fusion In the bilateral personalized dialogue generation, two crit- ical problems have to be addressed for appropriate persona expression: (1) when to express persona, and (2) whose persona should be expressed. Therefore, we propose dynamic persona-aware fusion to predict the presence of the bilateral personas and adaptively fuse them into the encodings for the further personalized response generation. Fig. 4. shows the structure of the dynamic persona-aware fusion module. The persona-aware means that the presence of the persona in the generated response can be predicted with the dialogue contextual encoding OC obtained from the attention operation. The prediction probability is used to dynamically weighted to the corresponded attention encoding for fusion. 1) Encoding Attention Mechanism: In order to effectively utilize the information of the encodings, we design differ- ent encoding attention mechanisms. Each encoding from the encoder participates in the unmasked multi-head attention mechanism. The masked multi-head attention mechanism is designed to avoid feeding the shifted-right ground-truth tokens when training. The prev represents the previously decoded output word, which turns into the outputs encoding Eprev with word embedding and position embedding. The EU is input into the unmasked multi-head attention network to obtain the user personalized encoding OU and the robot personalized encoding OR is obtained in the same way. The unmasked multi-head attention process is shown as follows: OU = Multi-head (Eprev, EU , EU ) (13) OR = Multi-head (Eprev, ER, ER) (14) where the Eprev is the query, the EU is both the key and the value in the unmasked multi-head mechanism, the operation of the robot personalized encoding OR is the same. The context encoding EC and the outputs encoding at the previous moment Eprev are used to obtain the dialogue con- textual encoding OC with the unmasked multi-head attention network, as is shown in equation (15): OC = Multi-head (Eprev, EC, EC) (15) where the Eprev is the query, the EC is both the key and the value in the unmasked multi-head mechanism. Furthermore, a masked multi-head attention network is used to obtain the previous outputs encodings Oprev, as is shown in equation(16): Oprev = MaskedMulti-Head (Eprev, Eprev, Eprev) (16) where the Eprev is the query, the key, and the value in the masked multi-head mechanism. 2) Persona Presence Prediction: The presence of the bi- lateral personas in the response is predicted for the dynamic persona-aware fusion of different encodings. To train a subnet- work for this task, we construct a heuristic script to label the utterance with three labels based on the presence of bilateral personas. The dialogue contextual encoding OC is used to predict the probability of three types of information, which JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 6 is presented in the response sentence. The loss function is designed as follows: LP (Î¸) = âˆ’ 3âˆ‘ j=1 lj log PÎ¸ (l = j | OC) (17) where the lj represents the label of different persona type, log PÎ¸ (l = j | OC) represents the probability of the persona type predicted in the generated response based on the dialogue contextual encoding OC. 3) Dynamic Encoding Fusion: To utilize personalized in- formation of different encodings, the dynamic encoding fusion is designed to adaptively control the persona presented in the generated response. The probability of three categories, which is used as the persona-aware weight for dynamic encoding fusion. Speciï¬cally, each category is operated with the softmax operation, which can be shown in the equation (18): PÎ¸ (l = j | OC) = exp O(j) C âˆ‘ i=3 exp O(i) C , j = 0, 1, 2 (18) where the O(j) C represents the dialogue contextual encoding OC corresponding to the j-th label, which is obtained with a two-layer perception network with global and average pooling. Each prediction probability is deï¬ned as the persona-aware weight as follows: Î± = PÎ¸ (l = 0 | OC) (19) Î² = PÎ¸ (l = 1 | OC) (20) Î³ = PÎ¸ (l = 2 | OC) (21) where the Î± represents the probability of the user personalized information presented in the response, the Î² represents the probability of the robot personalized information presented in the response, and the Î³ represents the probability that personalized information does not present in the response, which means the context-related. Three different encodings are dynamically weighted and fused, with the dialogue contextual encoding OC and the previous outputs encodings Oprev. These encodings together form the fused encoding Oenc, as is shown in equation (22): Oenc = Î±OU + Î²OR + (Î³ + 1)OC + Oprev (22) where Î± + Î² + Î³ = 1. After fusing the different encodings with the dynamic persona-aware fusion module, the fused encoding Oenc is input into the decoder for dialogue generation. D. Multi-task Learning for Dialogue Generation To train the proposed BPDG model, three different tasks have to be accomplished including language model task, persona prediction task and dialogue generation task. These tasks will be described below. 1) Language Model Task: A pre-trained model is ï¬rst utilized to initialize the parameters of the GPT2 framework. In order to bridge the gap between the data utilized in the pre-training and ï¬ne-tuning stage, the language model is then adopted to ï¬netune with the bilateral personalized dialogue dataset mentioned in Section IV-A. The language model is trained by optimizing the standard maximum log-likelihood loss, as shown in equation (23): LLM (Ï•) = âˆ’ âˆ‘ i log PÏ• (xi | xiâˆ’k, . . . , xiâˆ’1) (23) where Ï• represents the parameters of the language model, k is the size of the context window, and xiâˆ’k, . . . , xiâˆ’1, xi is sequence of tokens sampled from the training corpus. 2) Persona Prediction Task: The persona prediction task is to predict the persona presence according to the contextual encoding OC. The loss function is shown in the equation (17). As a result, the prediction probability is used to dynamically weighted the different encodings to get the fused encoding Oenc. Finally, the Oenc is input into the decoder for dialogue generation. 3) Dialogue Generation Task: The dialogue generation task is designed to to generate the bilateral personalized responses, the loss function of the dialogue generation task is shown as equation (24): LD(Ï•) = âˆ’ âˆ‘ i log PÏ• (yi | y0, . . . , yiâˆ’1, EC , EU , ER) = âˆ’ âˆ‘ i log PÏ• (yi | Oenc) (24) where yi represents the i-th word generated by the decoder, and y0, . . . , yiâˆ’1 is a sequence of previously generated words. Identically, the input of the decoder also can be written as the fused encoding. Finally, the joint loss function of the entire model is presented in equation (25): L(Ï•, Î¸) = LD(Ï•) + Î»1LLM (Ï•) + Î»2LP (Î¸) (25) where the Î»1 and Î»2 are the balance weights of the loss function of the language model task and the loss function of the persona prediction task respectively. E. Candidate Selection with CMIM After the dialogue generation via dynamic persona-aware fusion, the response is output with the beam search strategy. However, the top-ranked candidates with the beam search strategy are usually general, short, or even unrelated [35], so that responses related to both personas and history con- ditions often fail to achieve high ranking scores. To remedy this, the criterion of CMIM [36] is adopted to constrain the personalized and history information that reï¬‚ects in the response. Speciï¬cally, the BPDG method utilizes the beam search strategy to generate the best top-20 candidate list, and adopts the CMIM criterion to select the response with the largest conditional mutual information value as the ï¬nal response. JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 7Î—ğ‘|X,ğ‘ŒÎ—ğ‘ŒÎ—ğ‘‹Î—ğ‘ConditionalMutual InformationÎ—ğ‘Œ|ğ‘‹,ğ‘Î—ğ‘‹|ğ‘Œ,ğ‘ğš°ğ’€;ğ‘¿ğ’Î™ğ‘Œ;ğ‘‹;ğ‘Î™ğ‘‹;ğ‘|ğ‘ŒÎ™ğ‘Œ;ğ‘|ğ‘‹ Fig. 5. Illustration of conditional mutual information. The circles represent the information entropies of the different variables. The dashed circle represents the information entropy of the generated responses. 1) Conditional Mutual Information Modeling: In order to simplify the modeling process, the user persona U , the robot persona R, and personalized history information H can be regarded as the condition Z. The illustration of conditional mutual information is shown in Fig. 5. Given the different conditions, i.e., H, U, R in the same dialogue, the value of conditional mutual information CM Iv of the user input X and the robot generated candidate response Yi can be expressed as equation (26): CM Iv(Yi) â‰¡ I(Yi ; X | H , U , R) = H(Yi | H , U , R) ï¸¸ ï¸·ï¸· ï¸¸ Relevance Ranking âˆ’ H(Yi | X , H , U , R) ï¸¸ ï¸·ï¸· ï¸¸ Dialogue Generation (26) where the CMIM criterion can be modeled with two terms, i.e., the dialogue generation item and the relevance ranking item. According to the deï¬nition of the CMI [36], the maximum of the equation (26) can be achieved by solving the following optimization problem Y âˆ— = arg max Yi log P (Yi | X, Z) P (Yi | Z) (27) where the Y âˆ— represents the ï¬nal response in the top-20 candidate list. The P (Yi|X, Z) and P (Yi|Z) are corresponded to the dialogue generation term and relevance ranking term in equation (26) respectively. The P (Yi|X, Z) is the probability of the generated response conditioned on the input and the context with the word granu- larity, while the P (Yi|Z) is the relevance of the response to the contextual content with the sentence granularity. Therefore, the P (Yi|X, Z) and P (Yi|Z) of equation (27) are not optimized jointly. 2) Dialogue Generation: The P (Yi|X, Z) can be mod- eled with the BPDG model and calculated with the beam search score. By substituting the Z with H, U, R, the P (Yi|X, H, U, R) can be written as equation (28): log P (Yi | X, H, U, R) â‰¡ log PÏˆ (Yi | X, EH , EU , ER) = log PÏˆ (Yi | Oenc) (28) where the Ïˆ represents the parameters of the trained BPDG model, containing all the parameters in (25). 3) Relevance Ranking: After the candidate list is generated with the beam search strategy, each candidate can be ranked with relevance ranking. Given the condition Z, i.e., the user persona U , the robot persona R, and the personalized history H, the relevance probability is calculated as log P (Yi | H, U, R) = log PÏ†(Yi, H, U, R) log PÏ†(H, U, R) âˆ log PÏ†(Yi, H, U, R) (29) where the Ï† represents the parameters of the content relevance classiï¬er model trained on the corpus, the co-occurrence probability PÏ†(H, U, R) is not related to Yi which can be omitted, and the PÏ†(Yi, H, U, R) represents the co-occurrence probability of Yi, H, U and R in the same dialogue. Therefore, the relevance probability of each candidate can be modeled with the content relevance classiï¬er PÏ†(Yi, H, U, R). To construct the training corpus for content relevance classiï¬er, the Y , H, U , and R from the same dialogues are used as positive training samples, while the Y , H, U , and R from different dialogues are sampled as negative samples, which is inspired by the practice in [37]. The cross- entropy loss function used to train content relevance classiï¬er Ï† is as follows LÏ† = âˆ’ 1 N Nâˆ‘ i=0 ti log PÏ† (ti | (Y, H, U, R)) (30) where ti = 1 means the response Y appears in the same dialogue, and ti = 0 means the response Y does not appear in the same dialogue. 4) Candidate Selection: With the BPDG model and the content relevance classiï¬er, the optimization problem in (27) can be written as folows. Y âˆ— = arg max Yi log PÏˆ (Yi | Oenc) PÏ†(Yi, H, U, R) (31) In order to further ï¬ntune the relevance of the generated response to the contextual content, an additional penalty parameter Î»3 is introduced for the relevance ranking item. The too-large value of Î»3 may reduce the relevance of the ï¬nal response to the user input. Thus, the ï¬nal response can be selected by equation (32): Y âˆ— = arg max Yi log PÏˆ (Yi | Oenc) âˆ’ Î»3 log PÏ† (Yi, H, U, R) (32) IV. EXPERIMENTS A. Data Sets Description To evaluate the effectiveness of the BPDG method, exten- sive experiments are conducted based on the PersonalDialog dataset [10]. This dataset provides personalized proï¬les of both speakers, including three personal attributes i.e., â€œGenderâ€, â€œAreaâ€ and â€œIndividual interestsâ€. JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 8 Since in some cases of the original corpus, the personalized proï¬les are missing. We construct a heuristic script to select the data with complete personalized information of both parties. The constructed dialogue dataset is referred to as the bilateral personalized dataset in this article. The bilateral personalized dataset consists of 410K dialogues in total, where 400K is randomly sampled as the training set, and the rest 10K data as the validation set. The average length of each dialogue is about 3.5 rounds and the average length of each sentence is about 7.45 characters. The evaluation settings of the ECDT 3 are adopted, to test the performance of different methods in different contexts. Speciï¬cally, two test sets 4 (i.e., a random set and a biased set) are constructed for the evaluation. The random set is a collection of dialogues between both parties, most of which do not contain personas. It is constructed for testing the performance of different methods in a context where the two interacting parties do not intentionally show their personas. The biased test set is the dialogue set between both parties with personalized information, where the speaker tends to reveal personalized information about both parties during the conversation. It is used for testing the performance of different methods in the context where the speakers intentionally show their personas. B. Bilateral Persona Classiï¬er To better evaluate whether the response is bilateral persona- consistent or not, we design the bilateral persona classiï¬er as an objective metric, which is trained with the aforementioned personalized labels. Each sentence is labeled with one of the three labels: 0 for the sentence related to the persona of the user, 1 for the sentence related to the persona of the robot, and 2 for the sentence that does not contain the persona. The bilateral persona classiï¬er is used to evaluate whether the response Y contains the user persona U or the robot persona R. To calculate each probability of the respective category, the response Y with bilateral personas is concate- nated with < SEP >. After calculating each probability, the probability of category 0 and category 1 is added together as the probability of the bilateral personalized response. About 10K rounds of dialogues containing bilateral personas are randomly sampled from the bilateral personalized dataset, where the category ratio is 1:1:3. Then, we divide the above data into training, validation, and test set at a ratio of 8:1:1 to train the bilateral persona classiï¬er. The accuracy of the classiï¬er on the test set reaches 90.2% in a 5-fold cross- validation setting. C. Content Relevance Classiï¬er The content relevance classiï¬er is used for ranking the candidates under the criterion of the CMIM. After the can- didate list is generated by the BPDG model, we calculate the content relevance probability of each generated response co- occurring in the current dialogues under the conditions of the 3http://conference.cipsc.org.cn/smp2019/evaluation.html 4https://worksheets.codalab.org/worksheets/0x8f68b61a8b2249d7b314c6e8 00e2dace personalized history H, the user persona U , and the robot persona R. These conditions and each generated response are concatenated with < SEP > for calculating the content relevance probability. After the probability of each generated response is calculated, the ï¬nal response is selected to output. Speciï¬cally, the content relevance classiï¬er is trained on the bilateral personalized dataset, using the ERNIE-base model [38] to ï¬netune in the labeled dialogues. In the 5-fold cross- validation setting, the accuracy reaches 80.4%. D. Implementation Details The LCCC-base [39], a Chinese pre-trained model based on the GPT2 framework with a vocab of 13088 characters, is used to initialize the parameters of the encoder and decoder with transfer learning. According to [40], the shared weights of the encoder and decoder are adopted in this article, as it is beneï¬cial for improving the quality of generated responses. The encoder and decoder include 12 Transformer blocks, among which the self-attention heads are 12. The size of the token embedding is 768 and the context window is 512. The parameter dmodel = 512, n = 64, Î»1 = 0.2, Î»2 = 0.5, and Î»3 = 0.3. The beam search strategy adopted in the proposed method is to generate the candidate list with the BPDG model, where the beam size is set to 20. The content relevance classiï¬er is to calculate the relevance probability for each sentence in the candidates list under the criterion of the CMIM. The ï¬nal generated response Y âˆ— is selected to output. The BPDG model is ï¬netuned directly on the bilateral personalized dataset for 30 epochs, where the batch size is 64 with gradient accumulation, using the Noam optimization scheduler [41] with 2000 warm- up steps on two NVIDIA 2080 Ti GPUs. All the experimental codes are released at https://github.com/Lireanstar/BPDG 5. E. Compared Methods Several state-of-the-art baseline methods are compared with ours. These methods are described below: 1) S2S + Atten.: This method applies a three-layer Bi- GRU to project the input text into embeddings with a ï¬xed size. Another three-layer GRU utilizes an at- tention mechanism [42] for response generation. The word embedding parameters of encoder and decoder are initialized by the pre-trained word vector 6. The parameter weights of the GRU network are initialized with a uniform distribution [-0.05, 0.05]. The model is optimized by implementing the Adam optimization scheduler. 2) Trans.: The Trans. employs the Transformer [34] using the self-attention mechanism to generate responses. The model is initialized with the uniform distribution [-0.02, 0.02] and takes the concatenated dialogue history as input without using personas. We optimize the model by implementing the Noam [41] optimization scheduler. 3) TTransfo.: The TTransfo. is introduced by [28] opti- mizing a multi-task object for training. This model is 5Code and data will be publicly available 6https://github.com/Embedding/Chinese-Word-Vectors JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 9 initialized by the LCCC-base pre-trained model and ï¬ne- tunes directly on the bilateral personalized dataset only with the concatenated history. The Norm optimization scheduler is used for training the model with gradient accumulation (with batch size 64). 4) LConv.: The LConv. represents the multi-input model proposed in [27]. This model is initialized with the LCCC-base pre-trained model, which shares the param- eters of the encoder and decoder. The model ï¬netunes directly on the bilateral personalized dataset with the concatenated dialogue history. The Norm optimization scheduler is used for training the model with gradient accumulation (with batch size 64). 5) TTransfo.+P: It extends the TTransfo. by incorporating the speakerâ€™s persona. When ï¬ne-tuning, the contextual dialogues concatenated with the speakerâ€™s personalized information are input into the model. The Norm opti- mization scheduler is implemented for training, where the batch size is set to 64 with gradient accumulation. 6) LConv.+P: It extends the LConv. by incorporating the speakerâ€™s persona. When ï¬ne-tuning the contextual di- alogues concatenated with the speakerâ€™s personalized information are input into the model. The Norm opti- mization scheduler is implemented for training, where the batch size is set to 64 with gradient accumulation. 7) PWDWP: The PWDWP [12] is initialized by the LCCC- base pre-trained model and ï¬netunes on the bilateral personalized dataset. This model incorporates person- alized attributes embedding in the dialogue context for each speaker and devises a persona routing to weigh the persona-related encodings that are input into the decoder. The Norm optimization scheduler is implemented for training, where the batch size is set to 64 with gradient accumulation. This model is similar to our method, which is the strong baseline method in the explicit personalized dialogue system. V. AUTOMATIC EVALUATION In order to fully evaluate the effectiveness of the proposed method compared with the baseline methods, we choose various metrics for the automatic evaluation. In this section, we introduce these metrics and give a detailed analysis of the results. A. Objective Metrics Introduction 1) Bi-Persona Acc The Bi-Persona Acc is used to measure the degree of per- sonalization in the response. We extend the unilateral persona- consistent [12], which represents that the persona is consistent with the speaker, to the bilateral persona-consistent. The Bi- Persona Acc represents the bilateral persona classiï¬cation accuracy of the sentence which is not only consistent with the speakerâ€™s persona but also with the persona of the other party. Each generated response and the bilateral personas are input into the bilateral persona classiï¬er to obtain the Bi- Persona Acc. Therefore, we add the user and robot persona classiï¬cation accuracy together to obtain the possibility of the response that contains bilateral personalized information. The higher Bi-Persona Acc score means that the generated response is more personalized and more likely to be bilateral persona-consistent. 2) BLEU The BLEU (bilingual evaluation understudy) [43] is utilized to evaluate the quality of the text in translation. In dialogue generation, the BLEU is calculated with the weighted n-gram overlap between the ground-truth response Ì‚Y and generated responses Y âˆ—. The n-gram calculation is shown in the equation (33): Pn( Ì‚Y , Y âˆ—) = âˆ‘ k min (Cntclip(k, Ì‚Y ), Cntclip(k, Y âˆ—) ) âˆ‘ k Cnt(k, Ì‚Y ) (33) where k traverses all the n-grams candidates, the Ì‚Y and the Y âˆ— represent the ground-truth response and the generated response respectively, Cntclip(k, Y âˆ—) represents the clipped n-grams number in the generated response Y âˆ—, Cnt(k, Ì‚Y ) represents n-grams number in the ground-truth response Ì‚Y . The weight BP ( Ì‚Y , Y âˆ—) can be calculated as equation (34): BP ( Ì‚Y , Y âˆ—) = {1, if |Y âˆ—| > | Ì‚Y | e(1âˆ’| Ì‚Y |/|Y âˆ—|, if |Y âˆ—| â‰¤ | Ì‚Y | (34) where |Y âˆ—| represents the length of the generated response, | Ì‚Y | represents the length of the ground-truth response. The BLEU is calculated as follows: BLEU = BP ( Ì‚Y , Y âˆ—) Â· exp ( Nâˆ‘ n=1 wn log Pn( Ì‚Y , Y âˆ—) ) (35) where N is set to 2 and the weighted factor wn is set to 1/N , the percentile fraction we use is set to 1000, which is the same settings as the NLTK 7. The higher the BLEU score, the better the quality of the generated response. 3) F1 The F1 score is implemented to measure the accuracy of the model on the data set compared to the ground truth, which includes two parts: precision and recall. The precision means the proportion of words in the generated response contained in the ground-truth response, and the recall means the proportion of words in the ground-truth response contained in the generated response. The calculation of F1 score is the same as [44] and can be written as equation (36): F1 = 2 Ã— precision Â· recall precision + recall (36) 4) Distinct The Distinct [45] is adopted to measure the average score of the sum of unique unigrams and bigrams contained in the generated responses, which is divided by the total number of generated words. The equation can be written as follows: Distinct = 1 2 Ã— Cnt(Uuni) + Cnt(Ubi) N umtokens (37) where the Cnt(Uuni) represents the number of unigrams that are not repeated in the response compared with the ground- truth response, the N umtokens represents the total number 7https://github.com/nltk/nltk JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 10 TABLE I EXPERIMENTAL RESULTS OF FIVE METRICS ON RANDOM TEST SET Method BPAcc BLEU F1 Distinct PPL S2S + Atten. 9.71 3.18 4.32 0.098 87.41 Trans. 11.84 3.27 7.48 0.187 77.55 TTransfo. 15.43 6.33 10.40 0.255 47.48 TTransfo.+P 44.68 6.27 10.11 0.251 52.14 LConv. 12.41 3.38 7.52 0.243 51.32 LConv.+P 51.36 6.02 8.81 0.234 55.04 PWDWP 63.13 10.56 10.47 0.280 60.33 Ours 64.63 11.66 11.30 0.282 61.93 Ours, Î±=1 87.12 10.64 10.97 0.279 60.55 Ours, Î²=1 82.42 10.32 10.52 0.274 60.12 Ours, Î³=1 52.11 8.34 10.22 0.272 59.92 TABLE II EXPERIMENTAL RESULTS OF FIVE METRICS ON BAISED TEST SET Method BPAcc BLEU F1 Distinct PPL S2S + Atten. 22.42 4.32 4.71 0.116 97.53 Trans. 29.14 6.89 8.07 0.251 79.23 TTransfo. 43.12 15.22 15.93 0.268 49.59 TTransfo.+P 60.25 15.55 16.27 0.260 57.63 LConv. 42.73 10.03 9.09 0.270 56.41 LConv.+P 57.43 12.13 10.02 0.263 58.74 PWDWP 88.19 17.21 16.40 0.285 60.81 Ours 92.14 24.64 18.05 0.287 58.59 Ours, Î±=1 93.75 23.51 17.97 0.286 61.77 Ours, Î²=1 91.12 24.72 18.52 0.285 60.11 Ours, Î³=1 57.62 17.51 17.01 0.282 62.66 of generated words, the higher the distinct score, the more speciï¬c and diverse the response generated. 5) PPL The PPL (perplexity) [46] is widely used to measure the performance that the model predicts different utterances in the test set. For the ground-truth response Ì‚Y = {y1, y2, . . . , ym}, the perplexity is calculated by the trained model, and can be calculated as equation (38): Perplexity = exp (âˆ’ 1 N âˆ‘m i=1 ti) (38) ti = { log P (yi) + Îµ, if yi âˆˆ F log(P (unk)/|R|) + Îµ, if yi âˆˆ R (39) where the F represents the set of words in the frequent vocabulary and the R represents the set of words that are in the rare vocabulary, P (unk) represents the logits of unknown token predicted by the model. |R| is the number of words that are in the rare vocabulary, the Îµ is set to 10âˆ’8, which is used to ensure that logits are not zero. B. Results and Analysis Table I. and Table II. respectively show the comparison results of the proposed method and different baseline methods on ï¬ve metrics, and also present the performance of our method with different persona-aware weights. It can be seen from the results that, compared with the baseline methods, our method is superior to all metrics except the PPL. Further conclusions are that: (1) under the same automatic weighting setting, our method is better than the strong baseline method (i.e., PWDWP). On the random set, it outperforms with 1.5% in BPAcc, 1.1% in BLEU, 0.83% in F1, and 0.2% in Distinct. While on the biased set, our method outperforms with 3.95% in BPAcc, 7.43% in BLEU, 1.65% in F1, and 0.2% in Distinct. Especially on the baised set, our method is superior to the compared baseline methods. This shows that our method can generate more personalized and better responses. (2) It can be found that both in Table I. and Table II. the PPL scores in bold (i.e., 47.48 and 49.59) show that the best results of the PPL appear on the TTransfo, which is the method without incorporating the personalized information. However, the methods with personalized information (i.e., TTransfo.+P, LConv.+P, PWDWP, and our method) all obtain the higher PPL score. This indicates that generating responses with personalized information will hurt the PPL score. It occurs because the words involving the persona in social conversation are relatively rare. Such words may bring bias and lead to the worse perplexity score, which is in line with the results in [12], [44]. The baseline methods with a lower perplexity score tend to generate more general responses, thus they cannot generate responses that match the bilateral personas. As a result, the BPAcc scores of these baseline methods are relatively low. (3) Compared with the methods without personalized information (i.e., S2S + Atten., TTransfo. and LConv.), the methods with unilateral personalized information (i.e., TTransfo.+P, LConv.+P, and PWDWP) on the two test sets get higher BPAcc scores. Moreover, the method with bilateral personalized information (i.e., our method) has a higher BPAcc score on the two test sets than the strong baseline method with unilateral personalized information (i.e., PWDWP). This indicates the effectiveness of the proposed bilateral persona classiï¬er to evaluate the degree of person- alization and bilateral-consistent. (4) On the random set, the proposed method outperforms the other baseline methods that only incorporate the unilateral persona in BPAcc (i.e., 87.12 in bold). Similar trends are observed on the biased set (i.e., 93.75 in bold), which indicates that incorporating the other partyâ€™s personalized information in the decoding process is beneï¬cial to generate more personalized and more bilateral persona- consistent responses. (5) The proposed different persona- aware weights (i.e., Î±, Î², and Î³) can be used to control the persona presented in the generated response. The results of the two test sets show that under different context settings, it will improve the effect of personalized response generation with different persona-aware weights. This indicates that the proposed dynamic persona-aware fusion module is beneï¬cial to generate diversiï¬ed dialogue responses rich in bilateral personalized information. C. Ablation Study In order to test the performance of different modules on the proposed method, several ablation experiments are imple- mented as follows. (1) Each module of multi-task settings JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 11 TABLE III ABLATION RESULTS OF OUR PROPOSED METHOD ON RANDOM TEST SET Method BPAcc BLEU F1 Distinct PPL BPDG 64.63 11.66 11.30 0.282 61.93 w/o LM 40.42 9.21 10.27 0.273 60.17 w/o PAF 47.12 8.06 10.51 0.267 57.34 w/o PreT 42.19 4.71 8.74 0.247 88.89 w/o PEmb 43.24 9.12 11.01 0.270 63.12 w/o CMIM 60.14 8.13 8.83 0.301 61.93 TABLE IV ABLATION RESULTS OF OUR PROPOSED METHOD ON BIASED TEST SET Method BPAcc BLEU F1 Distinct PPL BPDG 92.14 24.64 18.05 0.287 58.59 w/o LM 69.54 20.96 17.87 0.254 62.50 w/o PAF 77.22 16.95 17.15 0.240 60.34 w/o PreT 74.57 13.56 15.12 0.232 77.52 w/o PEmb 74.41 18.79 17.44 0.249 61.19 w/o CMIM 87.11 17.22 16.12 0.312 58.59 is deleted respectively, including the language model (w/o LM) and the dynamic persona-aware fusion module (w/o PAF). (2) The pre-trained model is also deleted (w/o PreT) to test the performance of transfer learning. (3) The dialogue utterance with corresponded personas embedding (w/o PEmb) and the conditional mutual information maximum criterion (w/o CMIM) are deleted respectively to test the effect of different strategies on the BPDG method. Table III. and Table IV. show the ablation results. From the results, the further conclusion can be drawn that: (1) the LM module learns the languageâ€™s semantics from the dialogue context. Without the LM module, it will hurt the dynamic persona-aware fusion on the BPDG method. As a result, the BPAcc score will be decreased most. (2) The PAF module is beneï¬cial to generate more personalized and diversiï¬ed responses. The above different modules of multi- task learning prove to improve the total effect of personalized dialogue generation. (3) The pre-trained language model pro- vides a good parameter initialization for the BPDG method, which helps to improve training efï¬ciency by transferring the knowledge of the original domain to the target domain. (4) The PEmb strategy improves the ï¬nal performance by embedding the personalized attributes to the corresponded dialogue utterances. (5) More importantly, the CMIM criterion is effective to improve the BPAcc, BLEU, and F1 scores, but it may decrease the Distinct scores, which are bolded in Table III. and Table IV. This is because the sorting and selection steps from the candidates may hurt the diversity of the generated responses. VI. HUMAN EVALUATION We also perform a human evaluation to test the quality of responses generated by different methods. In this section, we introduce these metrics and give a comprehensive analysis of the results. TABLE V HUMAN EVALUATION ON THE RANDOM AND BIASED TEST SET. WITH * INDICATE THE SIGNIFICANT DIFFERENCE WITH THE BEST RESULT (T-TEST AND P-VALUE < 0.05) Method Sentence Bilateral Persona Context Fluency Consistency Consistency Rand Biasd Rand Biasd Rand Biasd S2S + Atten. 1.24* 1.14* 0.72* 0.91* 0.95* 1.12* Trans. 1.39* 1.42* 0.88* 1.07* 1.12* 1.38* TTransfo. 1.41* 1.37* 0.92* 1.19* 1.04* 1.41 TTransfo.+P 1.42* 1.43* 0.96* 1.27* 1.05* 1.39* LConv. 1.55* 1.54* 1.08* 1.42 1.01* 1.58 LConv.+P 1.70* 1.66* 1.12* 1.45 1.23 1.60* PWDWP 1.79 1.82 1.35 1.63* 1.25* 1.71 Ours 1.82 1.87* 1.41 1.74 1.27 1.75 Ours, Î±=1 1.79* 1.89* 1.42 1.80* 1.18* 1.71* Ours, Î²=1 1.81 1.85 1.47 1.72* 1.16* 1.67 Ours, Î³=1 1.76* 1.78* 1.09* 1.32* 1.24 1.69 Human Resp 1.89 1.90 1.07* 1.78 1.67 1.88 A. Subjective Metrics Introduction The evaluation metrics we choose are from three aspects, as is shown below. 1) Sentence ï¬‚uency Sentence ï¬‚uency represents the ï¬‚uency of responses gener- ated by different methods. 2) Bilateral persona consistency Bilateral persona consistency indicates whether the informa- tion is consistent with the userâ€™s or the robotâ€™s personalized information when generating a response by different methods. 3) Context consistency Context consistency means whether the response generated by different methods is consistent with the dialogue context. Three annotators are required to rate the quality of the responses according to the following three rating criteria: (1) +2: the response is not only semantically and grammatically related, but also bilateral persona-consistent. (2) +1: the re- sponse satisï¬es the grammatical rules and can be used as a response, but is too general and trivial. (3) +0: the response is semantically irrelevant, ungrammatical, or conï¬‚icts with the personalized information. B. Results and Analysis We sample 100 dialogue sessions from the original random and biased test set respectively for the human evaluation. The inter-annotator agreement is measured with Fleissâ€™s kappa Îº [47]. Particularly, the Îº value for sentence ï¬‚uency, bilateral persona consistency, and context consistency is 0.81, 0.71, 0.64 on the random test set respectively, and 0.75, 0.67, 0.61 on the biased test set respectively. The results indicate that the sentence ï¬‚uency, the bilateral persona consistency, and the context coherency of two test sets achieve substantial annotation agreement. Table V. shows the results of the human evaluation that the proposed method outperforms all baseline methods in all human metrics (t-test and p-value < 0.05). Further observa- tions indicate that (1) incorporating bilateral personas into the JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 12 All profiles: User: {\"Gender\": \"Male\", \"Area\": \"Shanghai\", \"Interests\": \"Sports; Movie\"} Robot: {\"Gender\": \"Female\", \"Area\": \"Guangzhou\", \"Interests\": \"Shopping; Makeups\"} User profile:{\"Gender\": \"Male\", \"Area\": \"Shanghai\", \"Interests\": \"Sports; Movie\"} Robot profile: {\"Gender\": \"Female\", \"Area\": \"Guangzhou\", \"Interests\": \"Shopping; Makeups\"} History: User: What are your recent arrangements? Robot: I plan to travel to Nanjing recently. Userâ€™s question: Nanjing is not fun, come to visit me? Ground-truth response: Are there any interesting attractions in Shanghai? S2S + Atten.: Ok, itâ€™s fun. Trans.: Ok, letâ€™s play fun. LConv.: Ok, letâ€™s play together. LConv. + P: Go to fun attractions together? TTransfo.: I have a chance to come to play with you! TTransfo. + P: I will come to Guangzhou. PWDWP: I will see you in Guangzhou, and play with you! Ours: Whatâ€™s fun in Shanghai? Iâ€™m in Guangzhou. Ours, = 1: Whatâ€™s fun in Shanghai? Ours, = 1: Why are you not so interesting about Nanjing? Iâ€™m in Guangzhou. Ours, = 1: Are there any fun places to travel? Fig. 6. Sampled responses generated by baseline methods and our method. generated response will impair the sentence ï¬‚uency and the context consistency, which corresponds to the high BPAcc score and the low PPL score in the automatic evaluation. Despite this, our method has achieved signiï¬cant advantages in ï¬‚uency and context consistency in two test sets compared with other methods. (2) The proposed dynamic persona-aware fusion module is designed to control different persona-aware weights for the personalized response generation. This module contributes to better bilateral persona consistency. At the same time, the bilateral persona consistency outperforms the human in the random test set and the test set. This shows that the proposed dynamic persona-aware fusion module is conducive to generating more personalized responses in both dialogue contexts. This observation is also in line with the BPAcc in automatic evaluation shown in Table I. and Table II. (3) Compared with the PWDWP method, the proposed BPDG has a great improvement in context consistency. This is due to the effect of the CMIM criterion, which selects the response from the generated the candidate list under the condition of the bilateral personas and the context. This observation also corresponds with the automatic evaluation results of BLEU and F1 metrics shown in Table III. and Table IV. C. Case Study The case study is shown in Fig. 6. The proposed method can generate a response consistent with the personas of both parties in the conversation. As we can see, the response generated by the TTransfo.+P and the PWDWP methods may be unilateral persona-consistent without incorporating the persona of the other party. The other baseline methods (i.e., S2S + Atten., TTrans., TTransfo., LConv., LConv.+P) may also generate a general response that lacks personalized information. The proposed BPDG method utilizes bilateral personalized information to generate responses that are in line with human cognition while constraining the contents of the generated responses with the CMIM criterion. Speciï¬cally, given the user input and the bilateral personas, our method can control the generated response content with different persona- aware weights. The Î± = 1 means that the userâ€™s personalized information presents in the response, such as Shanghai. The Î² = 1 means that the robotâ€™s personalized information presents in the response such as Guangzhou. The Î³ = 1 means that the personalized information does not present in the response, but it is relevant to the context, such as travel. VII. CONCLUSION In this article, we propose the BPDG method to generate more personalized and bilateral persona-consistent responses. Our method utilizes transfer learning via initializing parame- ters with a pre-trained model, then jointly trains the encoder, the dynamic persona-aware fusion module, and the decoder with multi-task learning. Experiments show that the transfer learning and multi-task learning method are conducive to improving the performance of dialogue in various metrics. In addition, the generated candidate responses are selected with the CMIM criterion, which shows that the quality of the ï¬nal response can be greatly improved. Extensive experiments are conducted to measure the effectiveness of the BPDG method, which shows that the BPDG has advantages in all metics but the PPL. The human evaluation results also prove that the BPDG method generates more ï¬‚uent, context-consistent, and bilateral persona-consistent responses than several state-of-the- art methods. It is worth noting that in open-domain dialogue, the human response is one-to-many, and the open-domain corpus cannot JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 13 contain all the situations. Moreover, people will respond and reason based on existing information during the conversation. In the future, we will explore other fusion strategy based dialogue generation methods with comprehensive reasoning of the existing information, to further improve the quality of the generated response. REFERENCES [1] D. Adiwardana, M.-T. Luong, D. R. So, J. Hall, N. Fiedel, R. Thoppilan, Z. Yang, A. Kulshreshtha, G. Nemade, Y. Lu et al., â€œTowards a human- like open-domain chatbot,â€ arXiv preprint arXiv:2001.09977, 2020. [2] A. de Barcelos Silva, M. M. Gomes, C. A. da Costa, R. da Rosa Righi, J. L. V. Barbosa, G. Pessin, G. De Doncker, and G. Federizzi, â€œIntelligent personal assistants: A systematic literature review,â€ Expert Systems with Applications, vol. 147, p. 113193, 2020. [3] A. Sheth, H. Y. Yip, A. Iyengar, and P. Tepper, â€œCognitive services and intelligent chatbots: current perspectives and special issue introduction,â€ IEEE Internet Computing, vol. 23, no. 2, pp. 6â€“12, 2019. [4] A. QueirÂ´os, A. G. Silva, P. SimËœoes, C. Santos, C. Martins, N. P. da Rocha, and M. Rodrigues, â€œSmartwalk: personas and scenarios deï¬ni- tion and functional requirements,â€ in 2018 2nd International Conference on Technology and Innovation in Sports, Health and Wellbeing (TISHW). IEEE, 2018, pp. 1â€“7. [5] S. Roller, Y.-L. Boureau, J. Weston, A. Bordes, E. Dinan, A. Fan, D. Gunning, D. Ju, M. Li, S. Poff et al., â€œOpen-domain conversational agents: Current progress, open problems, and future directions,â€ arXiv preprint arXiv:2006.12442, 2020. [6] M. Huang, X. Zhu, and J. Gao, â€œChallenges in building intelligent open- domain dialog systems,â€ ACM Transactions on Information Systems (TOIS), vol. 38, no. 3, pp. 1â€“32, 2020. [7] S. Zhang, E. Dinan, J. Urbanek, A. Szlam, D. Kiela, and J. Weston, â€œPersonalizing dialogue agents: I have a dog, do you have pets too?â€ in Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2018, pp. 2204â€“ 2213. [8] H. Song, W.-N. Zhang, Y. Cui, D. Wang, and T. Liu, â€œExploiting persona information for diverse generation of conversational responses,â€ in Proceedings of the 28th International Joint Conference on Artiï¬cial Intelligence. AAAI Press, 2019, pp. 5190â€“5196. [9] Q. Qian, M. Huang, H. Zhao, J. Xu, and X. Zhu, â€œAssigning personal- ity/proï¬le to a chatting machine for coherent conversation generation,â€ in Proceedings of the 27th International Joint Conference on Artiï¬cial Intelligence, 2018, pp. 4279â€“4285. [10] Y. Zheng, G. Chen, M. Huang, S. Liu, and X. Zhu, â€œPerson- alized dialogue generation with diversiï¬ed traits,â€ arXiv preprint arXiv:1901.09672, 2019. [11] M. Xu, P. Li, H. Yang, P. Ren, Z. Ren, Z. Chen, and J. Ma, â€œA neural topical expansion framework for unstructured persona-oriented dialogue generation,â€ arXiv preprint arXiv:2002.02153, 2020. [12] Y. Zheng, R. Zhang, M. Huang, and X. Mao, â€œA pre-training based per- sonalized dialogue generation model with persona-sparse data.â€ AAAI Press, 2020, pp. 9693â€“9700. [13] M. A. Walker, J. E. Cahn, and S. J. Whittaker, â€œImprovising linguistic style: Social and affective bases for agent personality,â€ in Proc. 1st Int. Conf. Autonom. Agents, 1997, pp. 96â€“105. [14] A. Isard, C. Brockmann, and J. Oberlander, â€œIndividuality and alignment in generated dialogues,â€ in Proceedings of the Fourth International Natural Language Generation Conference, 2006, pp. 25â€“32. [15] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever, â€œLanguage models are unsupervised multitask learners,â€ OpenAI blog, vol. 1, no. 8, 2019. [16] P. Koehn, â€œPharaoh: a beam search decoder for phrase-based statistical machine translation models,â€ in Conference of the Association for Machine Translation in the Americas. Springer, 2004, pp. 115â€“124. [17] L. R. Goldberg, â€œThe structure of phenotypic personality traits.â€ Amer- ican psychologist, vol. 48, no. 1, pp. 26â€“34, 1993. [18] F. Mairesse and M. Walker, â€œPersonage: Personality generation for dialogue,â€ in Proceedings of the 45th annual meeting of the association of computational linguistics, 2007, pp. 496â€“503. [19] J. Li, M. Galley, C. Brockett, G. Spithourakis, J. Gao, and B. Dolan, â€œA persona-based neural conversation model,â€ in Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2016, pp. 994â€“1003. [20] I. Sutskever, O. Vinyals, and Q. V. Le, â€œSequence to sequence learning with neural networks,â€ in Advances in neural information processing systems, 2014, pp. 3104â€“3112. [21] A. Madotto, Z. Lin, C.-S. Wu, and P. Fung, â€œPersonalizing dialogue agents via meta-learning,â€ in Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, 2019, pp. 5454â€“5459. [22] M. Yang, W. Huang, W. Tu, Q. Qu, Y. Shen, and K. Lei, â€œMultitask learning and reinforcement learning for personalized dialog generation: An empirical study,â€ IEEE Transactions on Neural Networks and Learning Systems, pp. 1â€“14, Mar. 2020. [23] K. Mo, S. Li, Y. Zhang, J. Li, and Q. Yang, â€œPersonalizing a di- alogue system with transfer reinforcement learning,â€ arXiv preprint arXiv:1610.02891, 2016. [24] D. Wang and T. F. Zheng, â€œTransfer learning for speech and language processing,â€ in 2015 Asia-Paciï¬c Signal and Information Processing Association Annual Summit and Conference (APSIPA). IEEE, 2015, pp. 1225â€“1237. [25] W.-N. Zhang, Q. Zhu, Y. Wang, Y. Zhao, and T. Liu, â€œNeural per- sonalized response generation as domain adaptation,â€ World Wide Web, vol. 22, no. 4, pp. 1427â€“1446, Jun. 2018. [26] P.-E. Mazare, S. Humeau, M. Raison, and A. Bordes, â€œTraining millions of personalized dialogue agents,â€ in Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 2018, pp. 2775â€“ 2779. [27] S. Golovanov, R. Kurbanov, S. Nikolenko, K. Truskovskyi, A. Tselousov, and T. Wolf, â€œLarge-scale transfer learning for natural language genera- tion,â€ in Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, 2019, pp. 6053â€“6058. [28] T. Wolf, V. Sanh, J. Chaumond, and C. Delangue, â€œTransfertransfo: A transfer learning approach for neural network based conversational agents,â€ arXiv preprint arXiv:1901.08149, 2019. [29] C. Zhu, M. Zeng, and X. Huang, â€œMulti-task learning for natural lan- guage generation in task-oriented dialogue,â€ in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 2019, pp. 1261â€“1266. [30] J. Gao, M. Galley, and L. Li, â€œNeural approaches to conversational ai,â€ in The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, 2018, pp. 1371â€“1374. [31] Y. Luan, C. Brockett, B. Dolan, J. Gao, and M. Galley, â€œMulti-task learning for speaker-role adaptation in neural conversation models,â€ in Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers), 2017, pp. 605â€“614. [32] S. Golovanov, A. Tselousov, R. Kurbanov, and S. I. Nikolenko, â€œLost in conversation: A conversational agent based on the transformer and transfer learning,â€ in The NeurIPSâ€™18 Competition. Springer, 2020, pp. 295â€“315. [33] V. L. Shiv, C. Quirk, A. Suri, X. Gao, K. Shahid, N. Govindarajan, Y. Zhang, J. Gao, M. Galley, C. Brockett et al., â€œMicrosoft icecaps: An open-source toolkit for conversation modeling,â€ in Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, 2019, pp. 123â€“128. [34] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Å. Kaiser, and I. Polosukhin, â€œAttention is all you need,â€ in Advances in neural information processing systems, 2017, pp. 5998â€“6008. [35] I. Kulikov, J. Lee, and K. Cho, â€œMulti-turn beam search for neural dialogue modeling,â€ arXiv preprint arXiv:1906.00141, 2019. [36] F. Fleuret, â€œFast binary feature selection with conditional mutual infor- mation,â€ Journal of Machine Learning Research, vol. 5, pp. 1531â€“1555, 2004. [37] Z. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, and R. Soricut, â€œAlbert: A lite bert for self-supervised learning of language representa- tions,â€ in International Conference on Learning Representations, 2019. [38] Y. Sun, S. Wang, Y. Li, S. Feng, X. Chen, H. Zhang, X. Tian, D. Zhu, H. Tian, and H. Wu, â€œErnie: Enhanced representation through knowledge integration,â€ arXiv preprint arXiv:1904.09223, 2019. [39] Y. Wang, P. Ke, Y. Zheng, K. Huang, Y. Jiang, X. Zhu, and M. Huang, â€œA large-scale chinese short-text conversation dataset,â€ arXiv preprint arXiv:2008.03946, 2020. [40] D. He, Y. Xia, T. Qin, L. Wang, N. Yu, T.-Y. Liu, and W.-Y. Ma, â€œDual learning for machine translation,â€ in Advances in neural information processing systems, 2016, pp. 820â€“828. [41] A. M. Rush, â€œThe annotated transformer,â€ in Proceedings of workshop for NLP open source software (NLP-OSS), 2018, pp. 52â€“60. [42] M.-T. Luong, H. Pham, and C. D. Manning, â€œEffective approaches to attention-based neural machine translation,â€ in Proceedings of the 2015 JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 14 Conference on Empirical Methods in Natural Language Processing, 2015, pp. 1412â€“1421. [43] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, â€œBleu: a method for automatic evaluation of machine translation,â€ in Proceedings of the 40th annual meeting of the Association for Computational Linguistics, 2002, pp. 311â€“318. [44] E. Dinan, V. Logacheva, V. Malykh, A. Miller, K. Shuster, J. Urbanek, D. Kiela, A. Szlam, I. Serban, R. Lowe et al., â€œThe second conversational intelligence challenge (convai2),â€ arXiv preprint arXiv:1902.00098, 2019. [45] J. Li, M. Galley, C. Brockett, J. Gao, and B. Dolan, â€œA diversity- promoting objective function for neural conversation models,â€ in Pro- ceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2016, pp. 110â€“119. [46] F. Huang, D. Wan, Z. Shao, P. Ke, J. Guan, Y. Niu, X. Zhu, and M. Huang, â€œCotk: An open-source toolkit for fast development and fair evaluation of text generation,â€ arXiv preprint arXiv:2002.00583, 2020. [47] J. J. Randolph, â€œFree-marginal multirater kappa (multirater k [free]): An alternative to ï¬‚eissâ€™ ï¬xed-marginal multirater kappa.â€ Online submission, 2005.","libVersion":"0.5.0","langs":""}